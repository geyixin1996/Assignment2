{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autograd in /anaconda3/lib/python3.7/site-packages (1.3)\n",
      "Requirement already satisfied: future>=0.15.2 in /anaconda3/lib/python3.7/site-packages (from autograd) (0.17.1)\n",
      "Requirement already satisfied: numpy>=1.12 in /anaconda3/lib/python3.7/site-packages (from autograd) (1.16.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from autograd import jacobian,hessian\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>LMT</th>\n",
       "      <th>AMD</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/11/2019</td>\n",
       "      <td>295.977448</td>\n",
       "      <td>22.959999</td>\n",
       "      <td>104.415909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/12/2019</td>\n",
       "      <td>299.992310</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>106.042915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/13/2019</td>\n",
       "      <td>300.298126</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>105.963547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/14/2019</td>\n",
       "      <td>296.924438</td>\n",
       "      <td>23.129999</td>\n",
       "      <td>106.052834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/15/2019</td>\n",
       "      <td>303.070068</td>\n",
       "      <td>23.680000</td>\n",
       "      <td>107.362373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date         LMT        AMD        MSFT\n",
       "0  2/11/2019  295.977448  22.959999  104.415909\n",
       "1  2/12/2019  299.992310  22.820000  106.042915\n",
       "2  2/13/2019  300.298126  22.850000  105.963547\n",
       "3  2/14/2019  296.924438  23.129999  106.052834\n",
       "4  2/15/2019  303.070068  23.680000  107.362373"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in daily price data on three stocks from the Internet\n",
    "price_data = pd.read_csv('https://sites.google.com/site/chnyyang/price_data.csv')\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date         LMT        AMD        MSFT  return_LMT  return_AMD  \\\n",
      "0    2/11/2019  295.977448  22.959999  104.415909    0.013565   -0.006098   \n",
      "1    2/12/2019  299.992310  22.820000  106.042915    0.001019    0.001315   \n",
      "2    2/13/2019  300.298126  22.850000  105.963547   -0.011234    0.012254   \n",
      "3    2/14/2019  296.924438  23.129999  106.052834    0.020698    0.023779   \n",
      "4    2/15/2019  303.070068  23.680000  107.362373   -0.006673    0.011402   \n",
      "5    2/19/2019  301.047821  23.950001  107.312767    0.006619    0.000000   \n",
      "6    2/20/2019  303.040497  23.950001  106.754837   -0.008756   -0.001253   \n",
      "7    2/21/2019  300.386932  23.920000  109.006500    0.008604    0.018395   \n",
      "8    2/22/2019  302.971436  24.360001  110.560745   -0.003777    0.014368   \n",
      "9    2/25/2019  301.827148  24.709999  111.178452   -0.000294   -0.020235   \n",
      "10   2/26/2019  301.738373  24.209999  111.945618    0.005558   -0.030153   \n",
      "11   2/27/2019  303.415314  23.480000  111.756317    0.013197    0.002130   \n",
      "12   2/28/2019  307.419434  23.530001  111.616837    0.000194    0.006375   \n",
      "13    3/1/2019  307.479034  23.680000  112.114990   -0.015446   -0.013091   \n",
      "14    3/4/2019  302.729797  23.370001  111.845993    0.003512    0.005563   \n",
      "15    3/5/2019  303.792908  23.500000  111.288048   -0.007980   -0.046383   \n",
      "16    3/6/2019  301.368591  22.410000  111.337868   -0.001022   -0.014726   \n",
      "17    3/7/2019  301.060608  22.080000  109.982887   -0.006798   -0.003170   \n",
      "18    3/8/2019  299.013855  22.010000  110.102448    0.011464    0.043162   \n",
      "19   3/11/2019  302.441650  22.959999  112.413887   -0.008147    0.023084   \n",
      "20   3/12/2019  299.977600  23.490000  113.200974    0.005068   -0.004683   \n",
      "21   3/13/2019  301.497772  23.379999  114.077728   -0.016280   -0.023952   \n",
      "22   3/14/2019  296.589539  22.820000  114.167389   -0.007906    0.020596   \n",
      "23   3/15/2019  294.244720  23.290001  115.482529    0.005031   -0.001718   \n",
      "24   3/18/2019  295.725159  23.250000  117.136406   -0.003494    0.118280   \n",
      "25   3/19/2019  294.691833  26.000000  117.216110   -0.002090   -0.011538   \n",
      "26   3/20/2019  294.075836  25.700001  117.086586    0.010237    0.085214   \n",
      "27   3/21/2019  297.086334  27.889999  119.776634   -0.016722   -0.054500   \n",
      "28   3/22/2019  292.118500  26.370001  116.618324    0.000374   -0.015169   \n",
      "29   3/25/2019  292.227783  25.969999  117.226074    0.002720   -0.010782   \n",
      "..         ...         ...        ...         ...         ...         ...   \n",
      "96   6/28/2019  363.540009  30.370001  133.960007   -0.005694    0.027330   \n",
      "97    7/1/2019  361.470001  31.200001  135.679993    0.016876    0.001282   \n",
      "98    7/2/2019  367.570007  31.240000  136.580002    0.007645   -0.001600   \n",
      "99    7/3/2019  370.380005  31.190001  137.460007   -0.001242    0.009939   \n",
      "100   7/5/2019  369.920013  31.500000  137.059998   -0.002000    0.017143   \n",
      "101   7/8/2019  369.179993  32.040001  136.960007    0.001490    0.034644   \n",
      "102   7/9/2019  369.730011  33.150002  136.460007   -0.004246    0.019306   \n",
      "103  7/10/2019  368.160004  33.790001  137.850006    0.000190   -0.021604   \n",
      "104  7/11/2019  368.230011  33.060001  138.399994    0.003313    0.004537   \n",
      "105  7/12/2019  369.450012  33.209999  138.899994   -0.004764    0.035531   \n",
      "106  7/15/2019  367.690002  34.389999  138.899994   -0.006364   -0.015702   \n",
      "107  7/16/2019  365.350006  33.849998  137.080002   -0.018831   -0.007386   \n",
      "108  7/17/2019  358.470001  33.599998  136.270004   -0.006305   -0.017857   \n",
      "109  7/18/2019  356.209991  33.000000  136.419998    0.002105   -0.014849   \n",
      "110  7/19/2019  356.959991  32.509998  136.619995    0.001877    0.010458   \n",
      "111  7/22/2019  357.630005  32.849998  138.429993    0.000475    0.019483   \n",
      "112  7/23/2019  357.799988  33.490002  139.289993    0.031023    0.018513   \n",
      "113  7/24/2019  368.899994  34.110001  140.720001    0.003849   -0.012900   \n",
      "114  7/25/2019  370.320007  33.669998  140.190002   -0.002322    0.010395   \n",
      "115  7/26/2019  369.459991  34.020000  141.339996    0.000433   -0.015873   \n",
      "116  7/29/2019  369.619995  33.480000  141.029999   -0.009821    0.011649   \n",
      "117  7/30/2019  365.989990  33.869999  140.350006   -0.010437   -0.100974   \n",
      "118  7/31/2019  362.170013  30.450001  136.270004    0.002540   -0.019376   \n",
      "119   8/1/2019  363.089996  29.860001  138.059998   -0.003250   -0.014066   \n",
      "120   8/2/2019  361.910004  29.440001  136.899994   -0.009616   -0.049253   \n",
      "121   8/5/2019  358.429993  27.990000  132.210007    0.023296    0.031083   \n",
      "122   8/6/2019  366.779999  28.860001  134.690002    0.006871    0.011435   \n",
      "123   8/7/2019  369.299988  29.190001  135.279999    0.021311    0.162042   \n",
      "124   8/8/2019  377.170013  33.919998  138.889999   -0.000424    0.007960   \n",
      "125   8/9/2019  377.010010  34.189999  137.710007         NaN         NaN   \n",
      "\n",
      "     return_MSFT  \n",
      "0       0.015582  \n",
      "1      -0.000748  \n",
      "2       0.000843  \n",
      "3       0.012348  \n",
      "4      -0.000462  \n",
      "5      -0.005199  \n",
      "6       0.021092  \n",
      "7       0.014258  \n",
      "8       0.005587  \n",
      "9       0.006900  \n",
      "10     -0.001691  \n",
      "11     -0.001248  \n",
      "12      0.004463  \n",
      "13     -0.002399  \n",
      "14     -0.004989  \n",
      "15      0.000448  \n",
      "16     -0.012170  \n",
      "17      0.001087  \n",
      "18      0.020994  \n",
      "19      0.007002  \n",
      "20      0.007745  \n",
      "21      0.000786  \n",
      "22      0.011519  \n",
      "23      0.014321  \n",
      "24      0.000680  \n",
      "25     -0.001105  \n",
      "26      0.022975  \n",
      "27     -0.026368  \n",
      "28      0.005211  \n",
      "29      0.002125  \n",
      "..           ...  \n",
      "96      0.012840  \n",
      "97      0.006633  \n",
      "98      0.006443  \n",
      "99     -0.002910  \n",
      "100    -0.000730  \n",
      "101    -0.003651  \n",
      "102     0.010186  \n",
      "103     0.003990  \n",
      "104     0.003613  \n",
      "105     0.000000  \n",
      "106    -0.013103  \n",
      "107    -0.005909  \n",
      "108     0.001101  \n",
      "109     0.001466  \n",
      "110     0.013248  \n",
      "111     0.006213  \n",
      "112     0.010266  \n",
      "113    -0.003766  \n",
      "114     0.008203  \n",
      "115    -0.002193  \n",
      "116    -0.004822  \n",
      "117    -0.029070  \n",
      "118     0.013136  \n",
      "119    -0.008402  \n",
      "120    -0.034258  \n",
      "121     0.018758  \n",
      "122     0.004380  \n",
      "123     0.026685  \n",
      "124    -0.008496  \n",
      "125          NaN  \n",
      "\n",
      "[126 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the period of daily price data: 2/11/2019-8/9/2019, 126 days in total\n",
    "date = price_data.loc[:,'Date']\n",
    "days = len(date)\n",
    "#print(days)\n",
    "\n",
    "#Read in the daily price data of LMT,AMD,MSFT seperately\n",
    "LMT = price_data.loc[:,'LMT']\n",
    "AMD = price_data.loc[:,'AMD']\n",
    "MSFT = price_data.loc[:,'MSFT']\n",
    "\n",
    "#Calculate the daily return of LMT,AMD,MSFT seperately\n",
    "return_LMT = np.diff(LMT)/LMT[:-1]\n",
    "return_AMD = np.diff(AMD)/AMD[:-1]\n",
    "return_MSFT = np.diff(MSFT)/MSFT[:-1]\n",
    "\n",
    "#Adding the daily return of LMT,AMD,MSFT to the original csv document\n",
    "price_data['return_LMT'] = pd.DataFrame(return_LMT)\n",
    "price_data['return_AMD'] = pd.DataFrame(return_AMD)\n",
    "price_data['return_MSFT'] = pd.DataFrame(return_MSFT)\n",
    "\n",
    "#You can look at the return of each stock by running the code in the next line\n",
    "print(price_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample mean of LMT is 0.001997\n",
      "The sample mean of AMD is 0.003748\n",
      "The sample mean of MSFT is 0.002291\n",
      "The covariance matrix is:\n",
      "[[1.19719993e-04 8.22279244e-05 4.88370930e-05]\n",
      " [8.22279244e-05 1.15503385e-03 2.05980390e-04]\n",
      " [4.88370930e-05 2.05980390e-04 1.49416239e-04]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the sample mean of each the three stocks\n",
    "sample_mean_LMT = np.mean(return_LMT)\n",
    "sample_mean_AMD = np.mean(return_AMD)\n",
    "sample_mean_MSFT = np.mean(return_MSFT)\n",
    "print(\"The sample mean of LMT is %.6f\" %sample_mean_LMT)\n",
    "print(\"The sample mean of AMD is %.6f\" %sample_mean_AMD)\n",
    "print(\"The sample mean of MSFT is %.6f\" %sample_mean_MSFT)\n",
    "\n",
    "#Calculating the covariance matrix\n",
    "list = []\n",
    "list.append(return_LMT)\n",
    "list.append(return_AMD)\n",
    "list.append(return_MSFT)\n",
    "b = np.transpose(list)\n",
    "covariance_matrix = np.cov(b, rowvar=False)\n",
    "print(\"The covariance matrix is:\") \n",
    "print(covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximize expected return of the portfolio \n",
    "# r is the array of expected returns for each stock\n",
    "# cov is the variance covariance matrix\n",
    "# maxVar is the restriction on maximun variance of the portfolio\n",
    "def maxReturn(r, cov, maxVar):\n",
    "    #number of constraints\n",
    "    n=3\n",
    "    \n",
    "    Q=np.zeros((len(r),len(r)));\n",
    "    f=-r;\n",
    "    c=0;\n",
    "\n",
    "    H=[]\n",
    "    k=[]\n",
    "    d=[]\n",
    "\n",
    "    for i in range(n):\n",
    "        H.append(np.zeros((len(r),len(r))))\n",
    "        k.append(np.zeros((len(r))))\n",
    "        d.append(0)\n",
    "\n",
    "    k[0]=np.array([1 for i in range(len(r))])\n",
    "    d[0]=-1\n",
    "\n",
    "    H[1]=2*cov\n",
    "    d[1]=-maxVar\n",
    "\n",
    "\n",
    "    #constraint setup\n",
    "    ineq_cons={'type': 'ineq',\n",
    "               'fun' : lambda p: np.array([-0.5*np.linalg.multi_dot([np.transpose(p),H[0],p])-np.dot(k[0],p)-d[0],\n",
    "                                           -0.5*np.linalg.multi_dot([np.transpose(p),H[1],p])-np.dot(k[1],p)-d[1]])}\n",
    "    #define objective function\n",
    "    def objective(p):\n",
    "        return 0.5*np.dot(np.transpose(p),np.dot(Q,p))+np.dot(f,p)+c\n",
    "    jacb  = jacobian(objective)\n",
    "    hessm = hessian(objective)\n",
    "\n",
    "    #initial guesses\n",
    "    g = len(r) #number of variables\n",
    "    p0 = np.zeros(g) \n",
    "\n",
    "\n",
    "    # variable bounds assignment\n",
    "    b = (0,1) #lower and upper bound\n",
    "    bnds = tuple(b for i in range(len(r)))\n",
    "    cons = ineq_cons #constraint assignment\n",
    "\n",
    "    solution = minimize(objective,p0,method='trust-constr', jac=jacb ,hess=hessm,\\\n",
    "                         bounds=bnds,constraints=cons)\n",
    "    x = solution.x\n",
    "\n",
    "\n",
    "    # show optimal objective value\n",
    "    print('Final Objective Value: %.7f' % -objective(x))\n",
    "\n",
    "    # print solution\n",
    "    print('Solution')\n",
    "    for i in range(len(r)):\n",
    "        print('p'+str(i+1)+' = %.7f' % x[i])\n",
    "    \n",
    "    return(-objective(x), x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Objective Value: 0.0023369\n",
      "Solution\n",
      "p1 = 0.4229203\n",
      "p2 = 0.1191918\n",
      "p3 = 0.4564938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.002336881136123105, array([0.42292028, 0.11919179, 0.45649381]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the maxium variance\n",
    "stdv_LMT = np.std(return_LMT)\n",
    "stdv_AMD = np.std(return_AMD)\n",
    "stdv_MSFT = np.std(return_MSFT)\n",
    "stdv_restriction = min(stdv_LMT,stdv_AMD,stdv_MSFT)\n",
    "var_restriction = stdv_restriction**2\n",
    "\n",
    "#Other inputs: exp_returns and variance matrix\n",
    "exp_returns = np.array([sample_mean_LMT,sample_mean_AMD,sample_mean_MSFT])\n",
    "var_cov_mtx = covariance_matrix\n",
    "max_var = var_restriction\n",
    "\n",
    "#Running the maximizing expected return framework\n",
    "maxReturn(exp_returns, var_cov_mtx, max_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: 0.42 unit should be invested in LMT, 0.12 unit should be invested in AMD and 0.46 unit should be invested in MSFT. The maximized daily return is 0.23%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>carats</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>4372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>4372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  carats  price\n",
       "0      1    0.75   2050\n",
       "1      1    1.00   4263\n",
       "2      1    1.00   4272\n",
       "3      1    1.01   4372\n",
       "4      1    1.01   4372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in dataset 'diamond.csv' from the Internet\n",
    "diamond = pd.read_csv('https://sites.google.com/site/chnyyang/diamonds.csv')\n",
    "diamond.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.816\n",
      "Model:                            OLS   Adj. R-squared:                  0.815\n",
      "Method:                 Least Squares   F-statistic:                     843.2\n",
      "Date:                Fri, 16 Aug 2019   Prob (F-statistic):          6.90e-140\n",
      "Time:                        15:47:41   Log-Likelihood:                -2861.2\n",
      "No. Observations:                 380   AIC:                             5728.\n",
      "Df Residuals:                     377   BIC:                             5740.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -3196.0383    169.255    -18.883      0.000   -3527.772   -2864.305\n",
      "x1          6155.6611    149.938     41.055      0.000    5861.789    6449.533\n",
      "x2          1130.9564     53.013     21.334      0.000    1027.053    1234.860\n",
      "==============================================================================\n",
      "Omnibus:                       70.749   Durbin-Watson:                   0.889\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              242.452\n",
      "Skew:                           0.799   Prob(JB):                     2.25e-53\n",
      "Kurtosis:                       6.572   Cond. No.                         16.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "# Multivariable linear regression\n",
    "x1 = diamond.loc[:,'carats'] \n",
    "x2 = diamond.loc[:,'color'] \n",
    "y = diamond.loc[:,'price']\n",
    "\n",
    "#Merge x1 and x2 into one variable and conduct linear regression\n",
    "x1 = np.column_stack((x1,x2))  \n",
    "x1 = sm.add_constant(x1)\n",
    "model = sm.OLS(y,x1,missing='drop')\n",
    "\n",
    "#Check the matrix of [1,x1,x2]\n",
    "#print(x1)\n",
    "\n",
    "# HC3 means we want heteroscedasticity robust standard errors\n",
    "result = model.fit(cov_type='HC3')\n",
    "\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    169.254972\n",
      "x1       149.937645\n",
      "x2        53.013097\n",
      "dtype: float64\n",
      "The robust error of the constant, carats and color is 169.254972,149.937645,53.013097 seperately.\n"
     ]
    }
   ],
   "source": [
    "# Reading standard errors  \n",
    "se_ols = result.bse \n",
    "print(se_ols)\n",
    "print(\"The robust error of the constant, carats and color is %.6f,%.6f,%.6f seperately.\" %(se_ols[0],se_ols[1],se_ols[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 25 percent quantiles of carats is 1.000 \n",
      "The 50 percent quantiles of carats is 1.030 \n",
      "The 75 percent quantiles of carats is 1.130 \n"
     ]
    }
   ],
   "source": [
    "carats = diamond.loc[:,'carats'] \n",
    "percentile25_carats = np.percentile(carats,25)\n",
    "percentile50_carats = np.percentile(carats,50)\n",
    "percentile75_carats = np.percentile(carats,75)\n",
    "print(\"The 25 percent quantiles of carats is %.3f \" % percentile25_carats)\n",
    "print(\"The 50 percent quantiles of carats is %.3f \" % percentile50_carats)\n",
    "print(\"The 75 percent quantiles of carats is %.3f \" % percentile75_carats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conditional covariance of the price where the carat is less than 25 percent quantile is 605255.5285 \n",
      "The conditional covariance of the price where the carat is between 25 percent quantile and 50 percent quantile is 294669.1239 \n",
      "The conditional covariance of the price where the carat is between 50 percent quantile and 75 percenr quantile is 201859.4439 \n",
      "The conditional covariance of the price where the carat is more than 75 percent quantile is 490783.5544 \n"
     ]
    }
   ],
   "source": [
    "#Finding the diamonds whose \"color\" is equal to 1 and weight less than 25% quantile\n",
    "sample_c1 = diamond.loc[(diamond['color']==1) & (diamond['carats'] <= percentile25_carats)]\n",
    "#Choosing the price data of the chosen diamonds\n",
    "price_c1 = sample_c1.loc[:,'price']\n",
    "#price_c1.head()\n",
    "variance_c1 = np.var(price_c1)\n",
    "\n",
    "#Finding the diamonds whose \"color\" is equal to 1 and weight between 25% and 50% quantile\n",
    "sample_c2 = diamond.loc[(diamond['color']==1) & (percentile25_carats < diamond['carats']) & (diamond['carats']<=percentile50_carats)]\n",
    "#Choosing the price data of the chosen diamonds\n",
    "price_c2 = sample_c2.loc[:,'price']\n",
    "#price_c2.head()\n",
    "variance_c2 = np.var(price_c2)\n",
    "\n",
    "#Finding the diamonds whose \"color\" is equal to 1 and weight between 50% and 75% quantile\n",
    "sample_c3 = diamond.loc[(diamond['color']==1) & (percentile50_carats < diamond['carats']) & (diamond['carats']<= percentile75_carats)]\n",
    "#Choosing the price data of the chosen diamonds\n",
    "price_c3 = sample_c3.loc[:,'price']\n",
    "#price_c3.head()\n",
    "variance_c3 = np.var(price_c3)\n",
    "\n",
    "#Finding the diamonds whose \"color\" is equal to 1 and weight more than 75% quantile\n",
    "sample_c4 = diamond.loc[(diamond['color']==1) & (percentile75_carats < diamond['carats'])]\n",
    "#Choosing the price data of the chosen diamonds\n",
    "price_c4 = sample_c4.loc[:,'price']\n",
    "#price_c4.head()\n",
    "variance_c4 = np.var(price_c4)\n",
    "\n",
    "print(\"The conditional covariance of the price where the carat is less than 25 percent quantile is %.4f \" %variance_c1)\n",
    "print(\"The conditional covariance of the price where the carat is between 25 percent quantile and 50 percent quantile is %.4f \" %variance_c2)\n",
    "print(\"The conditional covariance of the price where the carat is between 50 percent quantile and 75 percenr quantile is %.4f \" %variance_c3)\n",
    "print(\"The conditional covariance of the price where the carat is more than 75 percent quantile is %.4f \" %variance_c4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of U for diamonds whose color is equal to 1 and weight less than 25 percent quantile is 74539.98924\n",
      "The variance of U for diamonds whose color is equal to 1 and weight between 25 percent quantile and 50 percent quantile is 239126.40605\n",
      "The variance of U for diamonds whose color is equal to 1 and weight between 50 percent quantile and 75 percent quantile is 312353.25616\n",
      "The variance of U for diamonds whose color is equal to 1 and weight more than 75 percent quantile is 375155.89054\n",
      "Conclusion: The variance of U increases when carat increases.\n"
     ]
    }
   ],
   "source": [
    "#Reading the coefficients of the regression model\n",
    "b_ols = result.params\n",
    "#print(b_ols)\n",
    "#The coefficient of \"carats\" is b_ols[1]\n",
    "#The coefficient of \"color\" is b_ols[2]\n",
    "#The coefficient of constant is b_ols[0]\n",
    "β0 = b_ols[0]\n",
    "β1 = b_ols[1]\n",
    "β2 = b_ols[2]\n",
    "\n",
    "#Calculating the variance of U among the diamonds whose \"color\" is equal to 1 and weight less than 25% quantile\n",
    "x1_c1 = sample_c1.loc[:,'carats']\n",
    "x2_c1 = sample_c1.loc[:,'color']\n",
    "y_c1 = sample_c1.loc[:,'price']\n",
    "uhat_c1 = y_c1 - (β0 + β1*x1_c1 + β2*x2_c1)\n",
    "var_u_c1 = np.var(uhat_c1)\n",
    "#print(var_u_c1)\n",
    "\n",
    "#Calculating the variance of U among the diamonds whose \"color\" is equal to 1 and weight between 25% and 50% quantile\n",
    "x1_c2 = sample_c2.loc[:,'carats']\n",
    "x2_c2 = sample_c2.loc[:,'color']\n",
    "y_c2 = sample_c2.loc[:,'price']\n",
    "uhat_c2 = y_c2 - (β0 + β1*x1_c2 + β2*x2_c2)\n",
    "var_u_c2 = np.var(uhat_c2)\n",
    "#print(uhat_c2)\n",
    "\n",
    "#Calculating the variance of U among the diamonds whose \"color\" is equal to 1 and weight between 50% and 75% quantile\n",
    "x1_c3 = sample_c3.loc[:,'carats']\n",
    "x2_c3 = sample_c3.loc[:,'color']\n",
    "y_c3 = sample_c3.loc[:,'price']\n",
    "uhat_c3 = y_c3 - (β0 + β1*x1_c3 + β2*x2_c3)\n",
    "var_u_c3 = np.var(uhat_c3)\n",
    "#print(uhat_c3)\n",
    "\n",
    "#Calculating the variance of U among the diamonds whose \"color\" is equal to 1 and weight more than 75% quantile\n",
    "x1_c4 = sample_c4.loc[:,'carats']\n",
    "x2_c4 = sample_c4.loc[:,'color']\n",
    "y_c4 = sample_c4.loc[:,'price']\n",
    "uhat_c4 = y_c4 - (β0 + β1*x1_c4 + β2*x2_c4)\n",
    "var_u_c4 = np.var(uhat_c4)\n",
    "#print(uhat_c4)\n",
    "\n",
    "print(\"The variance of U for diamonds whose color is equal to 1 and weight less than 25 percent quantile is %.5f\" %var_u_c1)\n",
    "print(\"The variance of U for diamonds whose color is equal to 1 and weight between 25 percent quantile and 50 percent quantile is %.5f\" %var_u_c2)\n",
    "print(\"The variance of U for diamonds whose color is equal to 1 and weight between 50 percent quantile and 75 percent quantile is %.5f\" %var_u_c3)\n",
    "print(\"The variance of U for diamonds whose color is equal to 1 and weight more than 75 percent quantile is %.5f\" %var_u_c4)\n",
    "print(\"Conclusion: The variance of U increases when carat increases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean price at 50 percent quantile of the weight is 4059.8288\n"
     ]
    }
   ],
   "source": [
    "# Mean of price for diamonds with weight 50% quantile\n",
    "sample_e = diamond.loc[(diamond['carats']==percentile50_carats)]\n",
    "color_e = sample_e.loc[:,'color']\n",
    "mean_price = β0+β1*percentile50_carats+β2*np.mean(color_e)\n",
    "\n",
    "print(\"The mean price at 50 percent quantile of the weight is %.4f\" %mean_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is (2579.574931,5540.082649) \n"
     ]
    }
   ],
   "source": [
    "#Confidence interval for specific predictions\n",
    "color = diamond.loc[:,'color'] \n",
    "#Estimation of price(y)\n",
    "yhat = β0 + β1*carats + β2*color\n",
    "#two variables in the regrssion model, so ddof=2\n",
    "#Standard error of prediction\n",
    "se_yhat = np.std(yhat)/len(color)\n",
    "\n",
    "#Standard error of regression\n",
    "price_e = sample_e.loc[:,'price']\n",
    "color_e = sample_e.loc[:,'color']\n",
    "uhat = price_e - (β0 + β1*percentile50_carats + β2*color_e)\n",
    "ser = np.var(uhat)\n",
    "\n",
    "#For carats = percentile50_carats(assuming confidence interval is 95%) \n",
    "CI_upper = mean_price +1.96*math.sqrt(se_yhat**2+ser)\n",
    "CI_lower = mean_price -1.96*math.sqrt(se_yhat**2+ser)\n",
    "\n",
    "print(\"The confidence interval is (%.6f,%.6f) \" %(CI_lower,CI_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the variance of U increases when carat increases, so it is not reasonable to assume homoskedasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is not reasonable to assume homoskedasticity in this regression model, it is not reasonable to calculate Var(U) and use it calculate the confidence interval of the regression model for some values of the explanatory variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mkt-Rf</th>\n",
       "      <th>Rf</th>\n",
       "      <th>HD</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>VZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2/1990</td>\n",
       "      <td>-0.0785</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>1.31</td>\n",
       "      <td>7.83</td>\n",
       "      <td>8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/1990</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>1.49</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/1/1990</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>1.71</td>\n",
       "      <td>9.29</td>\n",
       "      <td>8.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/2/1990</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>1.75</td>\n",
       "      <td>9.09</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/1990</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>2.27</td>\n",
       "      <td>9.55</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Mkt-Rf      Rf    HD  AAPL    VZ\n",
       "0  1/2/1990 -0.0785  0.0057  1.31  7.83  8.41\n",
       "1  2/1/1990  0.0111  0.0057  1.49  7.85  7.73\n",
       "2  3/1/1990  0.0183  0.0064  1.71  9.29  8.12\n",
       "3  4/2/1990 -0.0336  0.0069  1.75  9.09  8.15\n",
       "4  5/1/1990  0.0842  0.0068  2.27  9.55  9.08"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in the data of the market returns and the adjusted closing price of HD, AAPL and VZ) from the Internet\n",
    "capm = pd.read_csv('https://sites.google.com/site/chnyyang/capm.csv')\n",
    "capm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Mkt-Rf      Rf     HD   AAPL     VZ  return_HD  return_AAPL  \\\n",
      "0     1/2/1990 -0.0785  0.0057   1.31   7.83   8.41   0.137405     0.002554   \n",
      "1     2/1/1990  0.0111  0.0057   1.49   7.85   7.73   0.147651     0.183439   \n",
      "2     3/1/1990  0.0183  0.0064   1.71   9.29   8.12   0.023392    -0.021529   \n",
      "3     4/2/1990 -0.0336  0.0069   1.75   9.09   8.15   0.297143     0.050605   \n",
      "4     5/1/1990  0.0842  0.0068   2.27   9.55   9.08  -0.048458     0.084817   \n",
      "5     6/1/1990 -0.0110  0.0063   2.16  10.36   8.65  -0.111111    -0.060811   \n",
      "6     7/2/1990 -0.0190  0.0068   1.92   9.73   8.71  -0.010417    -0.117163   \n",
      "7     8/1/1990 -0.1015  0.0066   1.90   8.59   7.54  -0.100000    -0.215367   \n",
      "8     9/4/1990 -0.0612  0.0060   1.71   6.74   8.33  -0.035088     0.059347   \n",
      "9    10/1/1990 -0.0192  0.0068   1.65   7.14   9.32   0.218182     0.198880   \n",
      "10   11/1/1990  0.0634  0.0057   2.01   8.56   9.70   0.079602     0.170561   \n",
      "11   12/3/1990  0.0246  0.0060   2.17  10.02   9.57   0.119816     0.290419   \n",
      "12    1/2/1991  0.0469  0.0052   2.43  12.93   8.75   0.127572     0.034029   \n",
      "13    2/1/1991  0.0718  0.0048   2.74  13.37   8.84   0.109489     0.187734   \n",
      "14    3/1/1991  0.0265  0.0044   3.04  15.88   9.27   0.065789    -0.191436   \n",
      "15    4/1/1991 -0.0027  0.0053   3.24  12.84   9.13   0.145062    -0.143302   \n",
      "16    5/1/1991  0.0365  0.0047   3.71  11.00   8.61   0.026954    -0.116364   \n",
      "17    6/3/1991 -0.0495  0.0042   3.81   9.72   8.63   0.076115     0.114198   \n",
      "18    7/1/1991  0.0424  0.0049   4.10  10.83   8.86   0.112195     0.148661   \n",
      "19    8/1/1991  0.0232  0.0046   4.56  12.44   9.23   0.010965    -0.065916   \n",
      "20    9/3/1991 -0.0159  0.0046   4.61  11.62   8.42   0.045553     0.039587   \n",
      "21   10/1/1991  0.0129  0.0042   4.82  12.08   8.83   0.058091    -0.011589   \n",
      "22   11/1/1991 -0.0418  0.0039   5.10  11.94   8.52   0.117647     0.110553   \n",
      "23   12/2/1991  0.1083  0.0038   5.70  13.26   9.06  -0.085965     0.148567   \n",
      "24    1/2/1992 -0.0059  0.0034   5.21  15.23   8.78   0.038388     0.044649   \n",
      "25    2/3/1992  0.0109  0.0028   5.41  15.91   8.28   0.012939    -0.137021   \n",
      "26    3/2/1992 -0.0266  0.0034   5.48  13.73   7.90  -0.036496     0.032047   \n",
      "27    4/1/1992  0.0108  0.0032   5.28  14.17   8.58   0.132576    -0.006351   \n",
      "28    5/1/1992  0.0030  0.0028   5.98  14.08   8.34  -0.046823    -0.195312   \n",
      "29    6/1/1992 -0.0234  0.0032   5.70  11.33   8.60   0.119298    -0.025596   \n",
      "..         ...     ...     ...    ...    ...    ...        ...          ...   \n",
      "90    7/1/1997  0.0733  0.0043  12.89   4.31  17.73  -0.052754     0.243619   \n",
      "91    8/1/1997 -0.0415  0.0041  12.21   5.36  17.68   0.105651    -0.003731   \n",
      "92    9/2/1997  0.0535  0.0044  13.50   5.34  19.65   0.069630    -0.213483   \n",
      "93   10/1/1997 -0.0379  0.0042  14.44   4.20  19.72   0.005540     0.040476   \n",
      "94   11/3/1997  0.0299  0.0039  14.52   4.37  22.00   0.050964    -0.260870   \n",
      "95   12/1/1997  0.0132  0.0048  15.26   3.23  22.44   0.027523     0.396285   \n",
      "96    1/2/1998  0.0014  0.0043  15.68   4.51  23.02   0.056122     0.290466   \n",
      "97    2/2/1998  0.0703  0.0039  16.56   5.82  22.32   0.059179     0.163230   \n",
      "98    3/2/1998  0.0477  0.0039  17.54   6.77  25.43   0.030787    -0.004431   \n",
      "99    4/1/1998  0.0073  0.0043  18.08   6.74  23.44   0.127212    -0.026706   \n",
      "100   5/1/1998 -0.0306  0.0040  20.38   6.56  22.96   0.057900     0.077744   \n",
      "101   6/1/1998  0.0318  0.0041  21.56   7.07  22.87   0.008349     0.206506   \n",
      "102   7/1/1998 -0.0246  0.0040  21.74   8.53  22.91  -0.089696    -0.099648   \n",
      "103   8/3/1998 -0.1608  0.0043  19.79   7.68  22.30   0.036887     0.222656   \n",
      "104   9/1/1998  0.0615  0.0046  20.52   9.39  24.48   0.102827    -0.025559   \n",
      "105  10/1/1998  0.0713  0.0032  22.63   9.15  27.08   0.142289    -0.139891   \n",
      "106  11/2/1998  0.0609  0.0031  25.85   7.87  28.32   0.230561     0.282084   \n",
      "107  12/1/1998  0.0615  0.0038  31.81  10.09  27.49  -0.011317     0.005946   \n",
      "108   1/4/1999  0.0350  0.0035  31.45  10.15  30.76  -0.013355    -0.154680   \n",
      "109   2/1/1999 -0.0408  0.0035  31.03   8.58  29.54   0.043506     0.031469   \n",
      "110   3/1/1999  0.0345  0.0043  32.38   8.85  26.50  -0.040148     0.280226   \n",
      "111   4/1/1999  0.0434  0.0037  31.08  11.33  29.76  -0.053411    -0.042365   \n",
      "112   5/3/1999 -0.0246  0.0034  29.42  10.85  28.27   0.140041     0.051613   \n",
      "113   6/1/1999  0.0477  0.0040  33.54  11.41  33.76  -0.009839     0.202454   \n",
      "114   7/1/1999 -0.0347  0.0038  33.21  13.72  33.26  -0.035531     0.172012   \n",
      "115   8/2/1999 -0.0138  0.0039  32.03  16.08  31.86   0.115829    -0.029851   \n",
      "116   9/1/1999 -0.0281  0.0039  35.74  15.60  34.98   0.103805     0.265385   \n",
      "117  10/1/1999  0.0613  0.0039  39.45  19.74  33.94   0.046134     0.221378   \n",
      "118  11/1/1999  0.0337  0.0036  41.27  24.11  33.34   0.302399     0.050601   \n",
      "119  12/1/1999  0.0772  0.0044  53.75  25.33  32.18        NaN          NaN   \n",
      "\n",
      "     return_VZ  \n",
      "0    -0.080856  \n",
      "1     0.050453  \n",
      "2     0.003695  \n",
      "3     0.114110  \n",
      "4    -0.047357  \n",
      "5     0.006936  \n",
      "6    -0.134328  \n",
      "7     0.104775  \n",
      "8     0.118848  \n",
      "9     0.040773  \n",
      "10   -0.013402  \n",
      "11   -0.085684  \n",
      "12    0.010286  \n",
      "13    0.048643  \n",
      "14   -0.015102  \n",
      "15   -0.056955  \n",
      "16    0.002323  \n",
      "17    0.026651  \n",
      "18    0.041761  \n",
      "19   -0.087757  \n",
      "20    0.048694  \n",
      "21   -0.035108  \n",
      "22    0.063380  \n",
      "23   -0.030905  \n",
      "24   -0.056948  \n",
      "25   -0.045894  \n",
      "26    0.086076  \n",
      "27   -0.027972  \n",
      "28    0.031175  \n",
      "29    0.083721  \n",
      "..         ...  \n",
      "90   -0.002820  \n",
      "91    0.111425  \n",
      "92    0.003562  \n",
      "93    0.115619  \n",
      "94    0.020000  \n",
      "95    0.025847  \n",
      "96   -0.030408  \n",
      "97    0.139337  \n",
      "98   -0.078254  \n",
      "99   -0.020478  \n",
      "100  -0.003920  \n",
      "101   0.001749  \n",
      "102  -0.026626  \n",
      "103   0.097758  \n",
      "104   0.106209  \n",
      "105   0.045790  \n",
      "106  -0.029308  \n",
      "107   0.118952  \n",
      "108  -0.039662  \n",
      "109  -0.102911  \n",
      "110   0.123019  \n",
      "111  -0.050067  \n",
      "112   0.194199  \n",
      "113  -0.014810  \n",
      "114  -0.042093  \n",
      "115   0.097928  \n",
      "116  -0.029731  \n",
      "117  -0.017678  \n",
      "118  -0.034793  \n",
      "119        NaN  \n",
      "\n",
      "[120 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading the adjusted closing price of HD,AAPL and VZ\n",
    "HD = capm.loc[:,'HD']\n",
    "AAPL = capm.loc[:,'AAPL']\n",
    "VZ = capm.loc[:,'VZ']\n",
    "\n",
    "#Calculate the monthly return of LMT,AMD,MSFT seperately\n",
    "return_HD = np.diff(HD)/HD[:-1]\n",
    "return_AAPL = np.diff(AAPL)/AAPL[:-1]\n",
    "return_VZ = np.diff(VZ)/VZ[:-1]\n",
    "\n",
    "#Adding the monthly return of LMT,AMD,MSFT to the original csv document\n",
    "capm['return_HD'] = pd.DataFrame(return_HD)\n",
    "capm['return_AAPL'] = pd.DataFrame(return_AAPL)\n",
    "capm['return_VZ'] = pd.DataFrame(return_VZ)\n",
    "\n",
    "#You can look at the return of each stock by running the code in the next line\n",
    "print(capm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The β of HD is -0.05836 \n",
      "The β of AAPL is -0.04861 \n",
      "The β of VZ is -0.17695 \n"
     ]
    }
   ],
   "source": [
    "#Calculating Rmkt and add it to \"capm.csv\"\n",
    "Rmkt = capm.loc[:,'Mkt-Rf'] + capm.loc[:,'Rf']\n",
    "capm['Rmkt'] = pd.DataFrame(Rmkt)\n",
    "\n",
    "#Calculating β(HD)\n",
    "#Choosing the non-Nan value in monthly return of HD, for our calculation, just omit the last one in variable \"Rmkt\", as daily return missed one value \n",
    "return_HD = return_HD[~np.isnan(return_HD)]\n",
    "cov_HD = np.cov(return_HD,Rmkt[0:len(Rmkt)-1])\n",
    "cov_HD = cov_HD[0,1]\n",
    "β_HD = cov_HD/np.var(Rmkt)\n",
    "#print(β_HD)  \n",
    "\n",
    "#Calculate β(AAPL)\n",
    "#Choosing the non-Nan value in monthly return of AAPL, for our calculation, just omit the last one in variable \"Rmkt\", as daily return missed one value \n",
    "return_AAPL = return_AAPL[~np.isnan(return_AAPL)]\n",
    "cov_AAPL = np.cov(return_AAPL,Rmkt[0:len(Rmkt)-1])\n",
    "cov_AAPL = cov_AAPL[0,1]\n",
    "β_AAPL = cov_AAPL/np.var(Rmkt)\n",
    "#print(β_AAPL) \n",
    "\n",
    "#Calculate β(VZ)\n",
    "#Choosing the non-Nan value in monthly return of VZ, for our calculation, just omit the last one in variable \"Rmkt\", as daily return missed one value \n",
    "return_VZ = return_VZ[~np.isnan(return_VZ)]\n",
    "cov_VZ = np.cov(return_VZ,Rmkt[0:len(Rmkt)-1])\n",
    "cov_VZ = cov_VZ[0,1]\n",
    "β_VZ = cov_VZ/np.var(Rmkt)\n",
    "#print(β_VZ)\n",
    "\n",
    "print(\"The β of HD is %.5f \" % β_HD)\n",
    "print(\"The β of AAPL is %.5f \" % β_AAPL)\n",
    "print(\"The β of VZ is %.5f \" % β_VZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The β of HD is -0.05836 means that when the market index decreases by 1%, the price of HD increases 0.058%; \n",
    "The β of AAPL is -0.04861 means that when the market index decreases by 1%, the price of HD increases 0.049%; \n",
    "The β of VZ is -0.17695 means that when the market index decreases by 1%, the price of HD increases 0.177%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(120)\n",
    "def bootSE(sample):\n",
    "    sample = np.array(sample)\n",
    "    sample = sample[~np.isnan(sample)]\n",
    "    \n",
    "    M = 200\n",
    "    \n",
    "    # Bootstrap\n",
    "    var_boot = np.array([])\n",
    "    data=[]\n",
    "    for bn in range(M):\n",
    "        data_bootn = choices(sample,k=len(sample))\n",
    "        data.append(np.array([data_bootn]))\n",
    "        \n",
    "    # the function only return the bootstrapped dataset\n",
    "    return(data)\n",
    "\n",
    "# Input into the bootstrap function called \"bootSE\" , for HD only \n",
    "#Step 1: Creating the tuple(Rmkt,RHD)\n",
    "sample_data_HD = pd.DataFrame({'Rmkt':Rmkt,'RHD':return_HD})\n",
    "sample_data_list_HD = sample_data_HD.values.tolist()\n",
    "sample_data_tuple_HD = tuple(sample_data_list_HD)\n",
    "#print(sample_data_tuple_HD)\n",
    "\n",
    "#Step 2: Getting 2000 “reshuffled” data for stock HD\n",
    "bootstrapped_data_HD = bootSE(sample_data_tuple_HD)\n",
    "#print(bootstrapped_data_HD)\n",
    "\n",
    "# Input into the bootstrap function called \"bootSE\" , for AAPL only \n",
    "#Step 1: Creating the tuple(Rmkt,RAAPL)\n",
    "sample_data_AAPL = pd.DataFrame({'Rmkt':Rmkt,'RAAPL':return_AAPL})\n",
    "sample_data_list_AAPL = sample_data_AAPL.values.tolist()\n",
    "sample_data_tuple_AAPL = tuple(sample_data_list_AAPL)\n",
    "#print(sample_data_tuple_AAPL)\n",
    "\n",
    "#Step 2: Getting 2000 “reshuffled” data for stock AAPL\n",
    "bootstrapped_data_AAPL = bootSE(sample_data_tuple_AAPL)\n",
    "#print(bootstrapped_data_AAPL)\n",
    "\n",
    "# Input into the bootstrap function called \"bootSE\" , for VZ only \n",
    "#Step 1: Creating the tuple(Rmkt,RVZ)\n",
    "sample_data_VZ = pd.DataFrame({'Rmkt':Rmkt,'RVZ':return_VZ})\n",
    "sample_data_list_VZ = sample_data_VZ.values.tolist()\n",
    "sample_data_tuple_VZ = tuple(sample_data_list_VZ)\n",
    "#print(sample_data_tuple_VZ)\n",
    "\n",
    "#Step 2: Getting 2000 “reshuffled” data for stock VZ\n",
    "bootstrapped_data_VZ = bootSE(sample_data_tuple_VZ)\n",
    "#print(bootstrapped_data_VZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bootstrapped estimate of βHD is: \n",
      "[ 0.2776048  -0.12549674  0.35189212 ...  0.07418326 -0.28899981\n",
      " -0.03729608]\n",
      "The bootstrapped estimate of βAAPL is: \n",
      "[-0.19687588  0.31495252 -0.63176099 ... -0.26058417  0.45489346\n",
      " -0.49606759]\n",
      "The bootstrapped estimate of βVZ is: \n",
      "[-0.22870413 -0.1467473  -0.2244584  ... -0.39847692  0.00289365\n",
      " -0.12557403]\n"
     ]
    }
   ],
   "source": [
    "#The framework of bootstrap\n",
    "np.random.seed(120)\n",
    "def bootSE(sample):\n",
    "    sample = np.array(sample)\n",
    "    #Only the last line of each tuple is NaN\n",
    "    sample = sample[0:len(sample)-1]\n",
    "    #Choosing the covariance in the covariance-variance matrix and calculate β, β is \"calculated_statistic\" in this command\n",
    "    calculated_statistic = np.cov(sample,rowvar=False)[0,1]/np.var(Rmkt)   \n",
    "    \n",
    "    M = 2000\n",
    "    \n",
    "    # Bootstrap\n",
    "    var_boot = np.array([])\n",
    "    data = []\n",
    "    for bn in range(M):\n",
    "        data_bootn = choices(sample,k=len(sample))\n",
    "        data.append(np.array([data_bootn]))\n",
    "        var_boot=np.append(var_boot,np.cov(data_bootn,rowvar=False)[0,1]/np.var(Rmkt))\n",
    "    \n",
    "    average_of_variances = np.average(var_boot)\n",
    "    \n",
    "    se = np.sqrt(np.sum((var_boot - average_of_variances)**2)/(M-1))\n",
    "    \n",
    "    # the function returns two results: the statistic and the standard error\n",
    "    return(calculated_statistic,se,var_boot)\n",
    "\n",
    "#2000 estimates of the bootstrapped estimates of βHD\n",
    "calculated_statistic,se,var_boot = bootSE(sample_data_tuple_HD) \n",
    "var_boot_HD = var_boot\n",
    "se_HD = se\n",
    "print(\"The bootstrapped estimate of βHD is: \")\n",
    "print(var_boot_HD)\n",
    "#print(len(var_boot_HD))    #Checking how many elements are in the bootstrapped estimate\n",
    "\n",
    "#2000 estimates of the bootstrapped estimates of βAAPL\n",
    "calculated_statistic,se,var_boot = bootSE(sample_data_tuple_AAPL) \n",
    "var_boot_AAPL = var_boot\n",
    "se_AAPL = se\n",
    "print(\"The bootstrapped estimate of βAAPL is: \")\n",
    "print(var_boot_AAPL)\n",
    "#print(len(var_boot_AAPL))    #Checking how many elements are in the bootstrapped estimate\n",
    "\n",
    "#2000 estimates of the bootstrapped estimates of βVZ\n",
    "calculated_statistic,se,var_boot = bootSE(sample_data_tuple_VZ) \n",
    "var_boot_VZ = var_boot\n",
    "se_VZ = se\n",
    "print(\"The bootstrapped estimate of βVZ is: \")\n",
    "print(var_boot_VZ)\n",
    "#print(len(var_boot_VZ))    #Checking how many elements are in the bootstrapped estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.025 quantiles for βHD is -0.547527 and 0.975 quantiles for βHD is 0.305929 \n",
      "So the bootstrapped Confidence Interval of βHD is (-0.547527,0.305929) \n",
      "the 0.025 quantiles for βAAPL is -1.027986 and 0.975 quantiles for βAAPL is 0.599707 \n",
      "So the bootstrapped Confidence Interval of βAAPL is (-1.027986,0.599707) \n",
      "the 0.025 quantiles for βVZ is -0.665702 and 0.975 quantiles for βVZ is 0.139120 \n",
      "So the bootstrapped Confidence Interval of βVZ is (-0.665702,0.139120) \n"
     ]
    }
   ],
   "source": [
    "#Computing the 2.5% quantile and 97.5% quantile for βHD\n",
    "CI_HD_lower = np.percentile(var_boot_HD,0.25)\n",
    "CI_HD_upper = np.percentile(var_boot_HD,97.5)\n",
    "print(\"the 0.025 quantiles for βHD is %.6f and 0.975 quantiles for βHD is %.6f \" %(CI_HD_lower,CI_HD_upper))\n",
    "print(\"So the bootstrapped Confidence Interval of βHD is (%.6f,%.6f) \" %(CI_HD_lower,CI_HD_upper))\n",
    "\n",
    "#Computing the 2.5% quantile and 97.5% quantile for βAAPL\n",
    "CI_AAPL_lower = np.percentile(var_boot_AAPL,0.25)\n",
    "CI_AAPL_upper = np.percentile(var_boot_AAPL,97.5)\n",
    "print(\"the 0.025 quantiles for βAAPL is %.6f and 0.975 quantiles for βAAPL is %.6f \" %(CI_AAPL_lower,CI_AAPL_upper))  \n",
    "print(\"So the bootstrapped Confidence Interval of βAAPL is (%.6f,%.6f) \" %(CI_AAPL_lower,CI_AAPL_upper))\n",
    "\n",
    "#Computing the 2.5% quantile and 97.5% quantile for βVZ\n",
    "CI_VZ_lower = np.percentile(var_boot_VZ,0.25)\n",
    "CI_VZ_upper = np.percentile(var_boot_VZ,97.5)\n",
    "print(\"the 0.025 quantiles for βVZ is %.6f and 0.975 quantiles for βVZ is %.6f \" %(CI_VZ_lower,CI_VZ_upper))  \n",
    "print(\"So the bootstrapped Confidence Interval of βVZ is (%.6f,%.6f) \" %(CI_VZ_lower,CI_VZ_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HD and β of AAPL, we can not reject the null hypothesis \"β=0\", as the estimated β is in the bootstrapped confidence intetval; while for VZ, we can reject the null hypothesis \"β=0\", as the estimated β is out of the bootstrapped confidence intetval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              return_HD   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.008\n",
      "Method:                 Least Squares   F-statistic:                   0.08903\n",
      "Date:                Fri, 16 Aug 2019   Prob (F-statistic):              0.766\n",
      "Time:                        19:18:14   Log-Likelihood:                 131.79\n",
      "No. Observations:                 119   AIC:                            -259.6\n",
      "Df Residuals:                     117   BIC:                            -254.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0356      0.008      4.466      0.000       0.020       0.051\n",
      "Rmkt          -0.0588      0.197     -0.298      0.765      -0.445       0.327\n",
      "==============================================================================\n",
      "Omnibus:                       10.252   Durbin-Watson:                   1.790\n",
      "Prob(Omnibus):                  0.006   Jarque-Bera (JB):               10.419\n",
      "Skew:                           0.633   Prob(JB):                      0.00547\n",
      "Kurtosis:                       3.706   Cond. No.                         25.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "# Univariable linear regression\n",
    "y = capm.loc[:,'return_HD'] \n",
    "x = capm.loc[:,'Rmkt']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y,x,missing='drop')\n",
    "#print(x)\n",
    "\n",
    "# HC3 means we want heteroscedasticity robust standard errors\n",
    "result2 = model.fit(cov_type='HC3')\n",
    "\n",
    "print(result2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimates should be equal to the β calculated in quesion(b), as CAPM can be written as E(Ri)=βi*E(Rmkt)+(1-βi)*Rf. In this form, βi = βHD in question(h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The covariance between uhat and x is 0.000000\n",
      "Conclusion: Equation (2) can be consistently estimated with OLS\n"
     ]
    }
   ],
   "source": [
    "#Verifing whether OLS can be used in this regrssion model is verifing whether the regression model has homoskedasticity or not\n",
    "#Reading the results of the regression in question 3(h)\n",
    "b_ols = result2.params  # actual estimates\n",
    "α = b_ols[0]\n",
    "β = b_ols[1]\n",
    "y = capm.loc[:,'return_HD'] \n",
    "x = capm.loc[:,'Rmkt']\n",
    "\n",
    "\n",
    "#Calculating uhat and its variance\n",
    "uhat = y - (α + β*x)\n",
    "uhat_x = pd.DataFrame({'uhat':uhat,'return_HD':x})\n",
    "uhat_list_x = uhat_x.values.tolist()\n",
    "uhat_tuple_x = tuple(uhat_list_x)\n",
    "uhat_array_x = np.array(uhat_tuple_x)\n",
    "covmtx_x_uhat = np.cov(uhat_array_x[0:len(uhat_array_x)-1],rowvar=False)\n",
    "print(\"The covariance between uhat and x is %.6f\" %covmtx_x_uhat[0,1])\n",
    "print(\"Conclusion: Equation (2) can be consistently estimated with OLS\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
